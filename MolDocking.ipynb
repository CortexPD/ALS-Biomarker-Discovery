{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dyo30Md8cZN0"
      },
      "outputs": [],
      "source": [
        "# The code for PLAPT binding affinity prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMPm_n7CceC4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertModel, RobertaTokenizer, RobertaModel\n",
        "import re\n",
        "import onnxruntime\n",
        "import numpy as np\n",
        "from typing import List, Dict, Union\n",
        "from diskcache import Cache\n",
        "from tqdm import tqdm\n",
        "from contextlib import contextmanager, nullcontext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nd0PV7U3cgDu"
      },
      "outputs": [],
      "source": [
        "class PredictionModule:\n",
        "    def __init__(self, model_path: str = \"models/affinity_predictor.onnx\"):\n",
        "        self.session = onnxruntime.InferenceSession(model_path)\n",
        "        self.input_name = self.session.get_inputs()[0].name\n",
        "        self.mean = 6.51286529169358\n",
        "        self.scale = 1.5614094578916633\n",
        "\n",
        "    def convert_to_affinity(self, normalized: float) -> Dict[str, float]:\n",
        "        neg_log10_affinity_M = float((normalized * self.scale) + self.mean)\n",
        "        affinity_uM = float((10**6) * (10**(-neg_log10_affinity_M)))\n",
        "        return {\n",
        "            \"neg_log10_affinity_M\": neg_log10_affinity_M,\n",
        "            \"affinity_uM\": affinity_uM\n",
        "        }\n",
        "\n",
        "    def predict(self, batch_data: np.ndarray) -> List[Dict[str, float]]:\n",
        "        affinities = []\n",
        "        for feature in batch_data:\n",
        "            affinity_normalized = self.session.run(None, {self.input_name: [feature], 'TrainingMode': np.array(False)})[0][0][0]\n",
        "            affinities.append(self.convert_to_affinity(affinity_normalized))\n",
        "        return affinities\n",
        "\n",
        "class Plapt:\n",
        "    def __init__(self, prediction_module_path: str = \"models/affinity_predictor.onnx\", device: str = 'cuda', cache_dir: str = './embedding_cache', use_tqdm: bool = False):\n",
        "        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')\n",
        "        self.use_tqdm = use_tqdm\n",
        "\n",
        "        self.prot_tokenizer = BertTokenizer.from_pretrained(\"Rostlab/prot_bert\", do_lower_case=False)\n",
        "        self.prot_encoder = BertModel.from_pretrained(\"Rostlab/prot_bert\").to(self.device)\n",
        "\n",
        "        self.mol_tokenizer = RobertaTokenizer.from_pretrained(\"seyonec/ChemBERTa-zinc-base-v1\")\n",
        "        self.mol_encoder = RobertaModel.from_pretrained(\"seyonec/ChemBERTa-zinc-base-v1\").to(self.device)\n",
        "\n",
        "        self.prediction_module = PredictionModule(prediction_module_path)\n",
        "        self.cache = Cache(cache_dir)\n",
        "\n",
        "    @contextmanager\n",
        "    def progress_bar(self, total: int, desc: str):\n",
        "        if self.use_tqdm:\n",
        "            with tqdm(total=total, desc=desc) as pbar:\n",
        "                yield pbar\n",
        "        else:\n",
        "            yield nullcontext()\n",
        "\n",
        "    @staticmethod\n",
        "    def preprocess_sequence(seq: str) -> str:\n",
        "        return \" \".join(re.sub(r\"[UZOB]\", \"X\", seq))\n",
        "\n",
        "    def tokenize_molecule(self, mol_smiles: Union[str, List[str]]) -> torch.Tensor:\n",
        "        return self.mol_tokenizer(mol_smiles, padding=True, max_length=278, truncation=True, return_tensors='pt')\n",
        "\n",
        "    def tokenize_protein(self, prot_seq: Union[str, List[str]]) -> torch.Tensor:\n",
        "        preprocessed = [self.preprocess_sequence(seq) if isinstance(seq, str) else self.preprocess_sequence(seq[0]) for seq in prot_seq]\n",
        "        return self.prot_tokenizer(preprocessed, padding=True, max_length=3200, truncation=True, return_tensors='pt')\n",
        "\n",
        "    def encode_molecules(self, mol_smiles: List[str], batch_size: int) -> torch.Tensor:\n",
        "        embeddings = []\n",
        "        with self.progress_bar(len(mol_smiles), \"Encoding molecules\") as pbar:\n",
        "            for batch in self.make_batches(mol_smiles, batch_size):\n",
        "                cached_embeddings = [self.cache.get(smiles) for smiles in batch]\n",
        "                uncached_indices = [i for i, emb in enumerate(cached_embeddings) if emb is None]\n",
        "\n",
        "                if uncached_indices:\n",
        "                    uncached_smiles = [batch[i] for i in uncached_indices]\n",
        "                    tokens = self.tokenize_molecule(uncached_smiles)\n",
        "                    with torch.no_grad():\n",
        "                        new_embeddings = self.mol_encoder(**tokens.to(self.device)).pooler_output.cpu()\n",
        "                    for i, emb in zip(uncached_indices, new_embeddings):\n",
        "                        cached_embeddings[i] = emb\n",
        "                        self.cache[batch[i]] = emb\n",
        "\n",
        "                embeddings.extend(cached_embeddings)\n",
        "                if self.use_tqdm:\n",
        "                    pbar.update(len(batch))\n",
        "\n",
        "        return torch.stack(embeddings).to(self.device)\n",
        "\n",
        "    def encode_proteins(self, prot_seqs: List[str], batch_size: int) -> torch.Tensor:\n",
        "        embeddings = []\n",
        "        with self.progress_bar(len(prot_seqs), \"Encoding proteins\") as pbar:\n",
        "            for batch in self.make_batches(prot_seqs, batch_size):\n",
        "                cached_embeddings = [self.cache.get(seq) for seq in batch]\n",
        "                uncached_indices = [i for i, emb in enumerate(cached_embeddings) if emb is None]\n",
        "\n",
        "                if uncached_indices:\n",
        "                    uncached_seqs = [batch[i] for i in uncached_indices]\n",
        "                    tokens = self.tokenize_protein(uncached_seqs)\n",
        "                    with torch.no_grad():\n",
        "                        new_embeddings = self.prot_encoder(**tokens.to(self.device)).pooler_output.cpu()\n",
        "                    for i, emb in zip(uncached_indices, new_embeddings):\n",
        "                        cached_embeddings[i] = emb\n",
        "                        self.cache[batch[i]] = emb\n",
        "\n",
        "                embeddings.extend(cached_embeddings)\n",
        "                if self.use_tqdm:\n",
        "                    pbar.update(len(batch))\n",
        "\n",
        "        return torch.stack(embeddings).to(self.device)\n",
        "\n",
        "    @staticmethod\n",
        "    def make_batches(iterable: List, n: int = 1):\n",
        "        length = len(iterable)\n",
        "        for ndx in range(0, length, n):\n",
        "            yield iterable[ndx:min(ndx + n, length)]\n",
        "\n",
        "    def predict_affinity(self, prot_seqs: List[str], mol_smiles: List[str], prot_batch_size: int = 2, mol_batch_size: int = 16, affinity_batch_size: int = 128) -> List[Dict[str, float]]:\n",
        "        if len(prot_seqs) != len(mol_smiles):\n",
        "            raise ValueError(\"The number of proteins and molecules must be the same.\")\n",
        "\n",
        "        prot_encodings = self.encode_proteins(prot_seqs, prot_batch_size)\n",
        "        mol_encodings = self.encode_molecules(mol_smiles, mol_batch_size)\n",
        "\n",
        "        affinities = []\n",
        "        with self.progress_bar(len(prot_seqs), \"Predicting affinities\") as pbar:\n",
        "            for batch in self.make_batches(range(len(prot_seqs)), affinity_batch_size):\n",
        "                prot_batch = prot_encodings[batch]\n",
        "                mol_batch = mol_encodings[batch]\n",
        "                features = torch.cat((prot_batch, mol_batch), dim=1).cpu().numpy()\n",
        "                batch_affinities = self.prediction_module.predict(features)\n",
        "                affinities.extend(batch_affinities)\n",
        "                if self.use_tqdm:\n",
        "                    pbar.update(len(batch))\n",
        "\n",
        "        return affinities\n",
        "\n",
        "    def score_candidates(self, target_protein: str, mol_smiles: List[str], mol_batch_size: int = 16, affinity_batch_size: int = 128) -> List[Dict[str, float]]:\n",
        "        target_encoding = self.encode_proteins([target_protein], batch_size=1)\n",
        "        mol_encodings = self.encode_molecules(mol_smiles, mol_batch_size)\n",
        "\n",
        "        affinities = []\n",
        "        with self.progress_bar(len(mol_smiles), \"Scoring candidates\") as pbar:\n",
        "            for batch in self.make_batches(range(len(mol_smiles)), affinity_batch_size):\n",
        "                mol_batch = mol_encodings[batch]\n",
        "                repeated_target = target_encoding.repeat(len(batch), 1)\n",
        "                features = torch.cat((repeated_target, mol_batch), dim=1).cpu().numpy()\n",
        "                batch_affinities = self.prediction_module.predict(features)\n",
        "                affinities.extend(batch_affinities)\n",
        "                if self.use_tqdm:\n",
        "                    pbar.update(len(batch))\n",
        "\n",
        "        return affinities\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    plapt = Plapt()\n",
        "    target_protein = \"MKTVRQERLKSIVRILERSKEPVSGAQLAEELSVSRQVIVQDIAYLRSLGYNIVATPRGYVLAGG\"\n",
        "    candidate_molecules = ['CC#C[C@]1(O)CC[C@H]2[C@@H]3CC=C4C(=O)CC[C@]4(C)[C@H]3CC[C@]21C','CN1C=C(C=N1)S(=O)(=O)N2CCC3=CC4=C(C[C@@]3(C2)C(=O)C5=NC=CC(=C5)C(F)','C1CC(CCC1C2=CC=CC=C2)C3=C(C(=O)NC(=O)N3)CC4=CC(=CC=C4)C(F)(F)F','CC(C)C1=CC=C(C=C1)C2=CC(=O)C3=C(C2=O)C4=CC=CC=C4C5=CC=CC=C35','CC#C[C@@]1(CC[C@@H]2[C@@]1(C[C@@H](C3=C4CCC(=O)C=C4CC[C@@H]23)C5=CC=C(C=C5)N(C)C(C)C)C)O','CC(C)[C@@H]([C@@H](C1=CC=CC=C1)OC2=CC3=C(C=C2)N(N=C3)C4=CN(C(=O)C=C4)C)NC(=O)C(C)(F)F','O=C(OCC(=O)[C@@]4(O)[C@H](C)C[C@H]5[C@@H]6/C=C(\\C3=C\\c1c(cnn1c2ccccc2)C[C@@]3([C@H]6[C@@H](O)C[C@]45C)C)C)C','CC#C[C@]1(O)CC[C@H]2[C@@H]3CC=C4C(=O)CC[C@]4(C)[C@H]3CC[C@]21C','CC(C)C1=CC=C(C=C1)C2=CC(=O)C3=C(C2=O)C4=CC=CC=C4C5=CC=CC=C35','CN1C=C(C=N1)S(=O)(=O)N2CCC3=CC4=C(C[C@@]3(C2)C(=O)C5=NC=CC(=C5)C(F)(F)F)C=NN4C6=CC=C(C=C6)F']\n",
        "    scores = plapt.score_candidates(target_protein, candidate_molecules, mol_batch_size=16, affinity_batch_size=128)\n",
        "    print(\"\\nScore Candidates Results:\", scores)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
